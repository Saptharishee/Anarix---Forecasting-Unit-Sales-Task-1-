{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2oDl8b5IEza"
      },
      "source": [
        "# ARIMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nc_rYEYjFu2m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "data_path = \"/content/df_PREPROCESSED.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTpTNfy_NW8x",
        "outputId": "6fa6f36e-88a3-4c68-fe1d-0b249290dd4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'ID', 'date', 'Item Id', 'Item Name', 'ad_spend',\n",
              "       'anarix_id', 'units', 'unit_price', 'orderedrevenueamount', 'ROAS',\n",
              "       'day_of_week', 'week', 'month', 'quarter', 'cost_category'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U97EzUejL-NN"
      },
      "outputs": [],
      "source": [
        "item_name_imputer = SimpleImputer(strategy='most_frequent')\n",
        "df['Item Name'] = item_name_imputer.fit_transform(df['Item Name'].values.reshape(-1, 1)).flatten()\n",
        "ad_spend_imputer = SimpleImputer(strategy='median')\n",
        "df['ad_spend'] = ad_spend_imputer.fit_transform(df['ad_spend'].values.reshape(-1, 1)).flatten()\n",
        "\n",
        "knn_imputer = KNNImputer(n_neighbors=5)\n",
        "df[['ad_spend', 'unit_price']] = knn_imputer.fit_transform(df[['ad_spend', 'unit_price']]) # KNNImputer handles multiple columns correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERjBJCaBLcSX"
      },
      "outputs": [],
      "source": [
        "\n",
        "numeric_cols = ['ad_spend', 'unit_price',  'units']\n",
        "df[numeric_cols] = df[numeric_cols].astype(float)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOLKTBklNLHs",
        "outputId": "8eb9cbd6-2e51-40f6-e250-cac961aaaf1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'ID', 'date', 'Item Id', 'Item Name', 'ad_spend',\n",
              "       'anarix_id', 'units', 'unit_price', 'orderedrevenueamount', 'ROAS',\n",
              "       'day_of_week', 'week', 'month', 'quarter', 'cost_category'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBvsSG8zMExS"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_size = int(0.8 * len(df))\n",
        "train, test = df.iloc[:train_size], df.iloc[train_size:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4IacxG5MLR6",
        "outputId": "3f63bc86-ae75-4065-dc83-9e376f130459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                               SARIMAX Results                                \n",
            "==============================================================================\n",
            "Dep. Variable:                  units   No. Observations:                80373\n",
            "Model:               SARIMAX(1, 1, 1)   Log Likelihood             -452814.345\n",
            "Date:                Fri, 02 Aug 2024   AIC                         905634.690\n",
            "Time:                        15:27:14   BIC                         905662.573\n",
            "Sample:                             0   HQIC                        905643.236\n",
            "                              - 80373                                         \n",
            "Covariance Type:                  opg                                         \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "ar.L1          0.0880      0.000    213.068      0.000       0.087       0.089\n",
            "ma.L1         -0.9962      0.000  -5379.225      0.000      -0.997      -0.996\n",
            "sigma2      4582.6631      0.779   5879.535      0.000    4581.135    4584.191\n",
            "===================================================================================\n",
            "Ljung-Box (L1) (Q):                   0.05   Jarque-Bera (JB):      166156310716.36\n",
            "Prob(Q):                              0.83   Prob(JB):                         0.00\n",
            "Heteroskedasticity (H):               3.46   Skew:                            63.64\n",
            "Prob(H) (two-sided):                  0.00   Kurtosis:                      7045.73\n",
            "===================================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
          ]
        }
      ],
      "source": [
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "p = 1\n",
        "d = 1\n",
        "q = 1\n",
        "\n",
        "\n",
        "arima_model = SARIMAX(train['units'], order=(p, d, q))\n",
        "arima_result = arima_model.fit()\n",
        "\n",
        "\n",
        "print(arima_result.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRNrbatoMOBE",
        "outputId": "55cb3d5f-5ed1-4edf-dbf8-3118d24b5c24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Root Mean Squared Error (RMSE): 35.32235463277331\n",
            "Mean Squared Error (MSE): 1247.668736803402\n",
            "Mean Absolute Error (MAE): 9.521394898266374\n",
            "R2 Score: -0.009068256063791802\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "start = len(train)\n",
        "end = len(train) + len(test) - 1\n",
        "predictions = arima_result.predict(start=start, end=end, dynamic=False)\n",
        "\n",
        "mse = mean_squared_error(test['units'], predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(test['units'], predictions)\n",
        "r2 = r2_score(test['units'], predictions)\n",
        "\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "print(f'R2 Score: {r2}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng2BNs4HMtXY"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_data_path = \"/content/test.csv\"\n",
        "test_df = pd.read_csv(test_data_path)\n",
        "\n",
        "\n",
        "test_df['Item Name'] = item_name_imputer.transform(test_df[['Item Name']].values.reshape(-1, 1)).flatten()\n",
        "test_df['ad_spend'] = ad_spend_imputer.transform(test_df[['ad_spend']].values.reshape(-1, 1)).flatten()\n",
        "test_df[['ad_spend', 'unit_price']] = knn_imputer.transform(test_df[['ad_spend', 'unit_price']])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_df = test_df.sort_values('date')\n",
        "test_df.set_index('date', inplace=True)\n",
        "\n",
        "future_predictions = arima_result.predict(start=len(df), end=len(df) + len(test_df) - 1)\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_df['ID'],\n",
        "    'TARGET': future_predictions.values\n",
        "})\n",
        "\n",
        "submission.to_csv('submission_arima.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZzVKrOxSdQ0"
      },
      "source": [
        "# LSTM & GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KOkTrDU2ESJ"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmsDd0L_PEdJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "import numpy as np\n",
        "\n",
        "data_path = \"/content/df_PREPROCESSED.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "item_name_imputer = SimpleImputer(strategy='most_frequent')\n",
        "df['Item Name'] = item_name_imputer.fit_transform(df[['Item Name']].values.reshape(-1, 1)).flatten()\n",
        "\n",
        "ad_spend_imputer = SimpleImputer(strategy='median')\n",
        "df['ad_spend'] = ad_spend_imputer.fit_transform(df[['ad_spend']].values.reshape(-1, 1)).flatten()\n",
        "\n",
        "knn_imputer = KNNImputer(n_neighbors=5)\n",
        "df[['ad_spend', 'unit_price']] = knn_imputer.fit_transform(df[['ad_spend', 'unit_price']])\n",
        "\n",
        "df['ad_spend_per_unit'] = df['ad_spend'] / df['units']\n",
        "df['revenue_per_unit'] = df['orderedrevenueamount'] / df['units']\n",
        "\n",
        "numeric_cols = ['ad_spend', 'unit_price', 'orderedrevenueamount', 'ROAS', 'ad_spend_per_unit', 'revenue_per_unit', 'units']\n",
        "df[numeric_cols] = df[numeric_cols].astype(float)\n",
        "\n",
        "df = df.sort_values('date')\n",
        "df.set_index('date', inplace=True)\n",
        "\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df.dropna(inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnC1EkQlPV7u"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "features = df[['ad_spend', 'unit_price']].values\n",
        "target = df['units'].values\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "def create_sequences(data, target, seq_length):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:i + seq_length])\n",
        "        y.append(target[i + seq_length])\n",
        "    return np.array(X), np.array(y)\n",
        "seq_length = 10\n",
        "X, y = create_sequences(scaled_features, target, seq_length)\n",
        "train_size = int(0.8 * len(X))\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkcGCKiCPbsg",
        "outputId": "6ea847a1-570a-4a1b-fa8e-3b99920752d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - loss: 8332.7764 - val_loss: 10590.3623\n",
            "Epoch 2/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 11673.6777 - val_loss: 10594.5020\n",
            "Epoch 3/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - loss: 6922.0645 - val_loss: 10589.5254\n",
            "Epoch 4/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 7127.6045 - val_loss: 10590.5361\n",
            "Epoch 5/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 12321.7002 - val_loss: 10598.5967\n",
            "Epoch 6/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 12066.7363 - val_loss: 10589.4316\n",
            "Epoch 7/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - loss: 10219.9150 - val_loss: 10597.1387\n",
            "Epoch 8/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 7471.3721 - val_loss: 10591.8369\n",
            "Epoch 9/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - loss: 11573.2783 - val_loss: 10587.2197\n",
            "Epoch 10/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - loss: 6165.1968 - val_loss: 10596.9121\n",
            "Epoch 11/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - loss: 7455.1992 - val_loss: 10587.7842\n",
            "Epoch 12/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - loss: 17584.4570 - val_loss: 10597.4004\n",
            "Epoch 13/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 4520.2769 - val_loss: 10586.8926\n",
            "Epoch 14/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - loss: 5428.9771 - val_loss: 10591.4033\n",
            "Epoch 15/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - loss: 4886.0728 - val_loss: 10588.2500\n",
            "Epoch 16/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - loss: 6645.5024 - val_loss: 10591.0146\n",
            "Epoch 17/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - loss: 6844.6641 - val_loss: 10592.7119\n",
            "Epoch 18/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - loss: 9027.3662 - val_loss: 10598.5518\n",
            "Epoch 19/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - loss: 14949.6289 - val_loss: 10588.5996\n",
            "Epoch 20/20\n",
            "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - loss: 5697.2778 - val_loss: 10591.6914\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lumNLIXdP6zY",
        "outputId": "6af4fa19-95df-40c8-bd05-911cd73ab332"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2684.2102\n",
            "Mean Squared Error on test data: 2003.3486328125\n"
          ]
        }
      ],
      "source": [
        "\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Mean Squared Error on test data: {loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_xNu_80P7-o",
        "outputId": "722b3421-8447-4e2e-9ebc-fae54e52733c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
            "Root Mean Squared Error (RMSE): 2145511.414096443\n",
            "Mean Squared Error (MSE): 4603219228018.119\n",
            "Mean Absolute Error (MAE): 897936.2242565965\n",
            "R2 Score: -0.0026469109638107557\n"
          ]
        }
      ],
      "source": [
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "predictions = scaler.inverse_transform(np.concatenate((predictions, np.zeros((predictions.shape[0], scaled_features.shape[1] - 1))), axis=1))[:, 0]\n",
        "y_test_inverse = scaler.inverse_transform(np.concatenate((y_test.reshape(-1, 1), np.zeros((y_test.shape[0], scaled_features.shape[1] - 1))), axis=1))[:, 0]\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "mse = mean_squared_error(y_test_inverse, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test_inverse, predictions)\n",
        "r2 = r2_score(y_test_inverse, predictions)\n",
        "\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "print(f'R2 Score: {r2}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kguZe9Zu2KUO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHHdv4Y-2UUo"
      },
      "source": [
        "## Bi LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF_jubvvMxMo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "import numpy as np\n",
        "data_path = \"/content/df_PREPROCESSED.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "\n",
        "item_name_imputer = SimpleImputer(strategy='most_frequent')\n",
        "df['Item Name'] = item_name_imputer.fit_transform(df[['Item Name']].values.reshape(-1, 1)).flatten()\n",
        "ad_spend_imputer = SimpleImputer(strategy='median')\n",
        "df['ad_spend'] = ad_spend_imputer.fit_transform(df[['ad_spend']].values.reshape(-1, 1)).flatten()\n",
        "knn_imputer = KNNImputer(n_neighbors=5)\n",
        "df[['ad_spend', 'unit_price']] = knn_imputer.fit_transform(df[['ad_spend', 'unit_price']])\n",
        "\n",
        "\n",
        "numeric_cols = ['ad_spend', 'unit_price', 'orderedrevenueamount', 'ROAS']\n",
        "df[numeric_cols] = df[numeric_cols].astype(float)\n",
        "df = df.sort_values('date')\n",
        "df.set_index('date', inplace=True)\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df.dropna(inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TFskXfvT098"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "features = df[['ad_spend', 'unit_price']].values\n",
        "target = df['units'].values\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "\n",
        "def create_sequences(data, target, seq_length):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:i + seq_length])\n",
        "        y.append(target[i + seq_length])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "seq_length = 10\n",
        "X, y = create_sequences(scaled_features, target, seq_length)\n",
        "\n",
        "\n",
        "train_size = int(0.8 * len(X))\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja5jEKkxT5tX",
        "outputId": "06ed6082-cb3c-42e3-e183-f4969287baaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 24ms/step - loss: 7289.6768 - val_loss: 8444.4609\n",
            "Epoch 2/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - loss: 2962.8770 - val_loss: 8396.1777\n",
            "Epoch 3/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 25ms/step - loss: 5744.2231 - val_loss: 8455.6191\n",
            "Epoch 4/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - loss: 3391.2961 - val_loss: 8429.2939\n",
            "Epoch 5/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - loss: 4821.7031 - val_loss: 8437.2686\n",
            "Epoch 6/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 23ms/step - loss: 7344.6113 - val_loss: 8436.6689\n",
            "Epoch 7/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - loss: 5074.8281 - val_loss: 8444.2246\n",
            "Epoch 8/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - loss: 5549.8325 - val_loss: 8467.7861\n",
            "Epoch 9/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - loss: 6106.0361 - val_loss: 8446.2314\n",
            "Epoch 10/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - loss: 2717.6558 - val_loss: 8425.5332\n",
            "Epoch 11/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 24ms/step - loss: 3106.6584 - val_loss: 8391.7012\n",
            "Epoch 12/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - loss: 5554.2139 - val_loss: 8436.2295\n",
            "Epoch 13/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - loss: 6523.1367 - val_loss: 8439.8975\n",
            "Epoch 14/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - loss: 8557.6680 - val_loss: 8330.7188\n",
            "Epoch 15/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - loss: 6977.7515 - val_loss: 8418.6582\n",
            "Epoch 16/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - loss: 5500.7744 - val_loss: 8421.8398\n",
            "Epoch 17/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 24ms/step - loss: 3577.1199 - val_loss: 8421.9492\n",
            "Epoch 18/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - loss: 7261.0820 - val_loss: 8353.2422\n",
            "Epoch 19/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 24ms/step - loss: 6177.6963 - val_loss: 8345.4316\n",
            "Epoch 20/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 3991.1619 - val_loss: 8353.6396\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(units=50, return_sequences=True), input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(units=50)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SFcT9hKT7pG",
        "outputId": "2e4557ab-15a3-4b5a-fd35-11a53cfdfb3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m486/486\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1669.5763\n",
            "Mean Squared Error on test data: 1576.6368408203125\n",
            "\u001b[1m486/486\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n",
            "Root Mean Squared Error (RMSE): 1903348.2061188722\n",
            "Mean Squared Error (MSE): 3622734393735.9287\n",
            "Mean Absolute Error (MAE): 604193.8949234871\n",
            "R2 Score: -0.001642189040704789\n"
          ]
        }
      ],
      "source": [
        "\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Mean Squared Error on test data: {loss}')\n",
        "\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "\n",
        "predictions = scaler.inverse_transform(np.concatenate((predictions, np.zeros((predictions.shape[0], scaled_features.shape[1] - 1))), axis=1))[:, 0]\n",
        "y_test_inverse = scaler.inverse_transform(np.concatenate((y_test.reshape(-1, 1), np.zeros((y_test.shape[0], scaled_features.shape[1] - 1))), axis=1))[:, 0]\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "mse = mean_squared_error(y_test_inverse, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test_inverse, predictions)\n",
        "r2 = r2_score(y_test_inverse, predictions)\n",
        "\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "print(f'R2 Score: {r2}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-r0ZPAj2jUc"
      },
      "source": [
        "## Bi GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZ-P42JQ2kvO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D_CDjx5T91X",
        "outputId": "ee6b6527-e2d3-4a0e-ab9b-13da8000bf93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 29ms/step - loss: 6653.3125 - val_loss: 8437.5811\n",
            "Epoch 2/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - loss: 4157.7788 - val_loss: 8446.1152\n",
            "Epoch 3/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - loss: 4667.1235 - val_loss: 8433.4326\n",
            "Epoch 4/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 27ms/step - loss: 5459.6128 - val_loss: 8437.9717\n",
            "Epoch 5/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 27ms/step - loss: 6985.6895 - val_loss: 8435.7949\n",
            "Epoch 6/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 27ms/step - loss: 5649.3086 - val_loss: 8447.9102\n",
            "Epoch 7/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 29ms/step - loss: 4295.7715 - val_loss: 8446.3721\n",
            "Epoch 8/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 28ms/step - loss: 9297.5000 - val_loss: 8444.6494\n",
            "Epoch 9/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 29ms/step - loss: 2774.4165 - val_loss: 8414.7363\n",
            "Epoch 10/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 29ms/step - loss: 7057.0830 - val_loss: 8419.2500\n",
            "Epoch 11/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 28ms/step - loss: 9458.2891 - val_loss: 8435.6270\n",
            "Epoch 12/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 34ms/step - loss: 3650.9343 - val_loss: 8441.1221\n",
            "Epoch 13/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 35ms/step - loss: 4833.7417 - val_loss: 8420.0205\n",
            "Epoch 14/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 34ms/step - loss: 4288.2637 - val_loss: 8424.2617\n",
            "Epoch 15/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 37ms/step - loss: 7886.1172 - val_loss: 8428.6201\n",
            "Epoch 16/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 35ms/step - loss: 3282.6707 - val_loss: 8436.2500\n",
            "Epoch 17/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 34ms/step - loss: 7329.3110 - val_loss: 8398.5391\n",
            "Epoch 18/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 34ms/step - loss: 5408.8853 - val_loss: 8463.7891\n",
            "Epoch 19/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 35ms/step - loss: 9379.0996 - val_loss: 8437.5283\n",
            "Epoch 20/20\n",
            "\u001b[1m1554/1554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 36ms/step - loss: 9476.6602 - val_loss: 8439.5752\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout, Bidirectional\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(GRU(units=50, return_sequences=True), input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(GRU(units=50)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMDD2GyKUA1U",
        "outputId": "f67842ad-6890-406a-a796-da85c0870355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m486/486\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1671.4817\n",
            "Mean Squared Error on test data: 1579.9788818359375\n",
            "\u001b[1m486/486\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step\n",
            "Root Mean Squared Error (RMSE): 1905364.41845312\n",
            "Mean Squared Error (MSE): 3630413567107.1963\n",
            "Mean Absolute Error (MAE): 597320.3522312896\n",
            "R2 Score: -0.003765387484101268\n"
          ]
        }
      ],
      "source": [
        "\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Mean Squared Error on test data: {loss}')\n",
        "\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "\n",
        "predictions = scaler.inverse_transform(np.concatenate((predictions, np.zeros((predictions.shape[0], scaled_features.shape[1] - 1))), axis=1))[:, 0]\n",
        "y_test_inverse = scaler.inverse_transform(np.concatenate((y_test.reshape(-1, 1), np.zeros((y_test.shape[0], scaled_features.shape[1] - 1))), axis=1))[:, 0]\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "mse = mean_squared_error(y_test_inverse, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test_inverse, predictions)\n",
        "r2 = r2_score(y_test_inverse, predictions)\n",
        "\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "print(f'R2 Score: {r2}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzuyZGIX1eOp"
      },
      "source": [
        "# Hyper Parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w1rSNvLn0Ooh",
        "outputId": "0d500673-11b5-4c74-db94-7b8052d0616d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (3.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2024.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras_tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras_tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras_tuner) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "pip install keras_tuner\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Iq3g1_a60g_3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from keras_tuner import Hyperband\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rvSKFsR5GHH6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_path = \"/content/df_PREPROCESSED.csv\"\n",
        "try:\n",
        "    df = pd.read_csv(data_path, on_bad_lines='warn')  # Warn on problematic lines\n",
        "except pd.errors.ParserError as e:\n",
        "    print(f\"Error occurred: {e}\")\n",
        "    problematic_row_index = int(str(e).split('row ')[-1])  # Extract row number from error message\n",
        "    with open(data_path, 'r') as file:\n",
        "        for i, line in enumerate(file):\n",
        "            if i == problematic_row_index:\n",
        "                print(f\"Problematic row ({i}): {line}\")\n",
        "                break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jFSdn5X_GJQo"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "numeric_cols = ['ad_spend', 'unit_price', 'units']\n",
        "df[numeric_cols] = df[numeric_cols].astype(float)\n",
        "\n",
        "# Normalize\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(df[numeric_cols])\n",
        "\n",
        "def create_sequences(data, seq_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:i + seq_length])\n",
        "        y.append(data[i + seq_length, -1])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "seq_length = 10\n",
        "X, y = create_sequences(scaled_data, seq_length)\n",
        "\n",
        "split = int(0.8 * len(X))\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "L2q9RxtCFilh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "outputId": "878eea6e-87d9-48cb-d83a-6beb4f25f92a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 42 Complete [00h 04m 25s]\n",
            "val_loss: 7.490970892831683e-05\n",
            "\n",
            "Best val_loss So Far: 7.431471021845937e-05\n",
            "Total elapsed time: 04h 46m 43s\n",
            "\n",
            "Search: Running Trial #43\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "256               |224               |units\n",
            "0.1               |0.1               |dropout_rate\n",
            "0.0003254         |0.00010393        |learning_rate\n",
            "4                 |10                |tuner/epochs\n",
            "2                 |4                 |tuner/initial_epoch\n",
            "2                 |2                 |tuner/bracket\n",
            "1                 |2                 |tuner/round\n",
            "0035              |0013              |tuner/trial_id\n",
            "\n",
            "Epoch 3/4\n",
            "\u001b[1m2010/2010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 109ms/step - loss: 2.8435e-05 - val_loss: 7.4748e-05\n",
            "Epoch 4/4\n",
            "\u001b[1m 527/2010\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:10\u001b[0m 88ms/step - loss: 1.8659e-04"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b90c042f9074>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                   project_name='helloworld')\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_hypermodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Save the build config for model loading later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=256, step=32),\n",
        "                   input_shape=(X_train.shape[1], X_train.shape[2]),\n",
        "                   return_sequences=True))\n",
        "    model.add(Dropout(rate=hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=256, step=32)))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
        "                  loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "tuner = Hyperband(build_model,\n",
        "                  objective='val_loss',\n",
        "                  max_epochs=10,\n",
        "                  hyperband_iterations=2,\n",
        "                  directory='my_dir',\n",
        "                  project_name='helloworld')\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=10, validation_split=0.2)\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "mse = best_model.evaluate(X_test, y_test)\n",
        "print(f'Mean Squared Error: {mse}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mTTN3HnJ3sB"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    units = hp.Int('units', min_value=32, max_value=128, step=32) # Reduced max value\n",
        "    model.add(LSTM(units=units,\n",
        "                   input_shape=(X_train.shape[1], X_train.shape[2]),\n",
        "                   return_sequences=True))\n",
        "    dropout_rate = hp.Float('dropout_rate', min_value=0.1, max_value=0.3, step=0.1) # Reduced max value\n",
        "    model.add(Dropout(rate=dropout_rate))\n",
        "    model.add(LSTM(units=units))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-3, sampling='LOG') # Reduced max value\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    print(\"Chosen hyperparameters:\")\n",
        "    print(f\"Units: {units}, Dropout Rate: {dropout_rate}, Learning Rate: {learning_rate}\")\n",
        "\n",
        "    return model\n",
        "tuner = Hyperband(build_model,\n",
        "                  objective='val_loss',\n",
        "                  max_epochs=10,\n",
        "                  hyperband_iterations=2,\n",
        "                  directory='my_dir',\n",
        "                  project_name='helloworld')\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=10, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3sRwTNpFjxM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36GsO-pyXeT5"
      },
      "source": [
        "# Py Spark Stacking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mN4W9Cm4XpOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44c311bd-8c33-4481-bd19-21c212e31573"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "mhbqlTroXgs3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "799f90c0-3e0b-4e3f-f029-79ec9e81acb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows in test_data: 1184\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when, lit\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml.regression import RandomForestRegressor, GBTRegressor, DecisionTreeRegressor\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.sql.functions import to_date\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"StackingModel\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "data_path = \"/content/df.csv\"\n",
        "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
        "\n",
        "\n",
        "df = df.withColumn(\"units\", when(col(\"units\") < 0, lit(0)).otherwise(col(\"units\")))\n",
        "df = df.withColumn(\"date\", to_date(col(\"date\")))  # Assuming 'date' is in a format that can be parsed to date\n",
        "df = df.withColumn(\"date\", col(\"date\").cast(StringType()))\n",
        "\n",
        "numeric_columns = [\"ad_spend\", \"unit_price\", \"units\"]\n",
        "for column in numeric_columns:\n",
        "    df = df.withColumn(column, col(column).cast(\"double\"))\n",
        "\n",
        "\n",
        "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# ID|      date|   Item Id|           Item Name|ad_spend|anarix_id|unit_price\n",
        "categorical_features = ['ID','date','Item Id', 'Item Name', 'anarix_id']\n",
        "numeric_features = ['ad_spend', 'unit_price']\n",
        "\n",
        "\n",
        "\n",
        "indexers = [StringIndexer(inputCol=feature, outputCol=feature + \"_index\", handleInvalid='keep') for feature in categorical_features]\n",
        "encoders = [OneHotEncoder(inputCol=feature + \"_index\", outputCol=feature + \"_ohe\") for feature in categorical_features]\n",
        "\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=numeric_features + [feature + \"_ohe\" for feature in categorical_features],\n",
        "    outputCol=\"features\",\n",
        "    handleInvalid=\"skip\"\n",
        ")\n",
        "\n",
        "\n",
        "rf_regressor = RandomForestRegressor(featuresCol=\"features\", labelCol=\"units\")\n",
        "gb_regressor = GBTRegressor(featuresCol=\"features\", labelCol=\"units\")\n",
        "dt_regressor = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"units\")\n",
        "\n",
        "\n",
        "pipeline_rf = Pipeline(stages=indexers + encoders + [assembler, rf_regressor])\n",
        "pipeline_gb = Pipeline(stages=indexers + encoders + [assembler, gb_regressor])\n",
        "pipeline_dt = Pipeline(stages=indexers + encoders + [assembler, dt_regressor])\n",
        "\n",
        "print(f\"Rows in test_data beofre model : {test_data.count()}\")\n",
        "\n",
        "\n",
        "rf_model = pipeline_rf.fit(train_data)\n",
        "gb_model = pipeline_gb.fit(train_data)\n",
        "dt_model = pipeline_dt.fit(train_data)\n",
        "\n",
        "\n",
        "rf_predictions = rf_model.transform(test_data).select(\"features\", \"prediction\", \"units\").withColumnRenamed(\"prediction\", \"rf_prediction\")\n",
        "gb_predictions = gb_model.transform(test_data).select(\"features\", \"prediction\", \"units\").withColumnRenamed(\"prediction\", \"gb_prediction\")\n",
        "dt_predictions = dt_model.transform(test_data).select(\"features\", \"prediction\", \"units\").withColumnRenamed(\"prediction\", \"dt_prediction\")\n",
        "\n",
        "\n",
        "meta_features = rf_predictions.join(gb_predictions, on=[\"features\", \"units\"], how=\"inner\")\n",
        "meta_features = meta_features.join(dt_predictions, on=[\"features\", \"units\"], how=\"inner\")\n",
        "meta_features = meta_features.select(\"features\", \"rf_prediction\", \"gb_prediction\", \"dt_prediction\", \"units\")\n",
        "\n",
        "\n",
        "assembler_meta = VectorAssembler(inputCols=[\"rf_prediction\", \"gb_prediction\", \"dt_prediction\"], outputCol=\"meta_features\")\n",
        "meta_features_assembled = assembler_meta.transform(meta_features)\n",
        "\n",
        "\n",
        "meta_features_assembled = meta_features_assembled.withColumn(\"units\", when(col(\"units\") < 0, lit(0)).otherwise(col(\"units\")))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"RandomForestRegressor details:\")\n",
        "print(rf_model.stages[-1])  # RandomForestRegressor details\n",
        "\n",
        "print(\"GBTRegressor details:\")\n",
        "print(gb_model.stages[-1])  # GBTRegressor details\n",
        "\n",
        "print(\"DecisionTreeRegressor details:\")\n",
        "print(dt_model.stages[-1])  # DecisionTreeRegressor details\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFhhQBIQPHgJ",
        "outputId": "bfbe723c-628c-4562-d18b-aefc9050d3d4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestRegressor details:\n",
            "RandomForestRegressionModel: uid=RandomForestRegressor_bbcd5c5c20d2, numTrees=20, numFeatures=5278\n",
            "GBTRegressor details:\n",
            "GBTRegressionModel: uid=GBTRegressor_2301eff558be, numTrees=20, numFeatures=5278\n",
            "DecisionTreeRegressor details:\n",
            "DecisionTreeRegressionModel: uid=DecisionTreeRegressor_2fc639d4f874, depth=5, numNodes=17, numFeatures=5278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if meta_features_assembled has data and valid 'units' values\n",
        "print(\"Number of rows in meta_features_assembled:\", meta_features_assembled.count())\n",
        "print(\"Summary of 'units' column:\")\n",
        "meta_features_assembled.select(\"units\").summary().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhtVA414Gy22",
        "outputId": "ee0fa6fb-dfc8-40b6-9c9b-08d75fb6d73b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in meta_features_assembled: 93\n",
            "Summary of 'units' column:\n",
            "+-------+------------------+\n",
            "|summary|             units|\n",
            "+-------+------------------+\n",
            "|  count|                93|\n",
            "|   mean|1.7526881720430108|\n",
            "| stddev|  5.51018013194569|\n",
            "|    min|               0.0|\n",
            "|    25%|               0.0|\n",
            "|    50%|               0.0|\n",
            "|    75%|               1.0|\n",
            "|    max|              46.0|\n",
            "+-------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of rows in each prediction DataFrame\n",
        "print(\"Number of rows in rf_predictions:\", rf_predictions.count())\n",
        "print(\"Number of rows in gb_predictions:\", gb_predictions.count())\n",
        "print(\"Number of rows in dt_predictions:\", dt_predictions.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1GUYG_5G0_Y",
        "outputId": "8758be91-2616-4da5-abc8-11ce05633be3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in rf_predictions: 93\n",
            "Number of rows in gb_predictions: 93\n",
            "Number of rows in dt_predictions: 93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_aG-fvOMkI4q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12e6e3d8-5b2f-41b8-f73b-ef3b4633a93e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) on test data = 5.753914048864514\n",
            "Mean Squared Error (MSE) on test data = 33.10752688172043\n",
            "Mean Absolute Error (MAE) on test data = 1.7526881720430108\n",
            "R2 Score on test data = -0.10227578932781056\n",
            "+--------------------+-------------------+------------------+------------------+-----+--------------------+--------------------+--------------------+----------+\n",
            "|            features|      rf_prediction|     gb_prediction|     dt_prediction|units|       meta_features|       rawPrediction|         probability|prediction|\n",
            "+--------------------+-------------------+------------------+------------------+-----+--------------------+--------------------+--------------------+----------+\n",
            "|(5278,[0,5127,513...|  5.282654889728369| 4.557603682205905|5.7592592592592595|  0.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5117,513...|  5.282654889728369| 4.557603682205905|5.7592592592592595|  0.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5106,513...|  5.282654889728369| 4.557603682205905|5.7592592592592595|  0.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5112,513...|  5.282654889728369| 4.557603682205905|5.7592592592592595|  0.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5097,513...|  5.282654889728369| 4.557603682205905|5.7592592592592595|  0.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5109,513...|  5.282654889728369| 4.557603682205905|5.7592592592592595|  0.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5110,513...|  5.282654889728369| 4.557603682205905|5.7592592592592595|  4.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5094,516...|0.43443612449934965|0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5087,516...|0.43443612449934965|0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5098,513...|  5.282654889728369| 4.557603682205905|5.7592592592592595|  2.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5091,513...|  5.282654889728369| 4.557603682205905|5.7592592592592595|  8.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5095,516...|0.43443612449934965|0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5077,516...|0.43443612449934965|0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5084,516...|0.43443612449934965|0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5020,513...|  5.282654889728369| 4.557603682205905|5.7592592592592595|  6.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5081,513...|  5.282654889728369| 4.557603682205905|5.7592592592592595|  5.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5081,516...|0.43443612449934965|0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5003,513...|  5.282654889728369| 4.557603682205905|5.7592592592592595| 11.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5072,516...|0.43443612449934965|0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5060,513...|  5.282654889728369| 4.557603682205905|5.7592592592592595|  8.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "+--------------------+-------------------+------------------+------------------+-----+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "meta_learner = LogisticRegression(featuresCol=\"meta_features\", labelCol=\"units\")\n",
        "stacking_model = meta_learner.fit(meta_features_assembled)\n",
        "\n",
        "\n",
        "final_predictions = stacking_model.transform(meta_features_assembled)\n",
        "\n",
        "\n",
        "evaluator = RegressionEvaluator(labelCol=\"units\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(final_predictions)\n",
        "print(f\"Root Mean Squared Error (RMSE) on test data = {rmse}\")\n",
        "\n",
        "mse = evaluator.setMetricName(\"mse\").evaluate(final_predictions)\n",
        "print(f\"Mean Squared Error (MSE) on test data = {mse}\")\n",
        "\n",
        "mae = evaluator.setMetricName(\"mae\").evaluate(final_predictions)\n",
        "print(f\"Mean Absolute Error (MAE) on test data = {mae}\")\n",
        "\n",
        "r2 = evaluator.setMetricName(\"r2\").evaluate(final_predictions)\n",
        "print(f\"R2 Score on test data = {r2}\")\n",
        "\n",
        "final_predictions.show(20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Schema of rf_predictions:\")\n",
        "rf_predictions.printSchema()\n",
        "rf_predictions.show(5)\n",
        "\n",
        "print(f\"Schema of gb_predictions:\")\n",
        "gb_predictions.printSchema()\n",
        "gb_predictions.show(5)\n",
        "\n",
        "print(f\"Schema of dt_predictions:\")\n",
        "dt_predictions.printSchema()\n",
        "dt_predictions.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVmvswra_i1G",
        "outputId": "a129d362-cb5d-455a-e505-e5daa36b6b50"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema of rf_predictions:\n",
            "root\n",
            " |-- features: vector (nullable = true)\n",
            " |-- rf_prediction: double (nullable = false)\n",
            " |-- units: double (nullable = true)\n",
            "\n",
            "+--------------------+-----------------+-----+\n",
            "|            features|    rf_prediction|units|\n",
            "+--------------------+-----------------+-----+\n",
            "|(5278,[0,5127,513...|5.282654889728369|  0.0|\n",
            "|(5278,[0,5117,513...|5.282654889728369|  0.0|\n",
            "|(5278,[0,5106,513...|5.282654889728369|  0.0|\n",
            "|(5278,[0,5112,513...|5.282654889728369|  0.0|\n",
            "|(5278,[0,5097,513...|5.282654889728369|  0.0|\n",
            "+--------------------+-----------------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "Schema of gb_predictions:\n",
            "root\n",
            " |-- features: vector (nullable = true)\n",
            " |-- gb_prediction: double (nullable = false)\n",
            " |-- units: double (nullable = true)\n",
            "\n",
            "+--------------------+-----------------+-----+\n",
            "|            features|    gb_prediction|units|\n",
            "+--------------------+-----------------+-----+\n",
            "|(5278,[0,5127,513...|4.557603682205905|  0.0|\n",
            "|(5278,[0,5117,513...|4.557603682205905|  0.0|\n",
            "|(5278,[0,5106,513...|4.557603682205905|  0.0|\n",
            "|(5278,[0,5112,513...|4.557603682205905|  0.0|\n",
            "|(5278,[0,5097,513...|4.557603682205905|  0.0|\n",
            "+--------------------+-----------------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "Schema of dt_predictions:\n",
            "root\n",
            " |-- features: vector (nullable = true)\n",
            " |-- dt_prediction: double (nullable = false)\n",
            " |-- units: double (nullable = true)\n",
            "\n",
            "+--------------------+------------------+-----+\n",
            "|            features|     dt_prediction|units|\n",
            "+--------------------+------------------+-----+\n",
            "|(5278,[0,5127,513...|5.7592592592592595|  0.0|\n",
            "|(5278,[0,5117,513...|5.7592592592592595|  0.0|\n",
            "|(5278,[0,5106,513...|5.7592592592592595|  0.0|\n",
            "|(5278,[0,5112,513...|5.7592592592592595|  0.0|\n",
            "|(5278,[0,5097,513...|5.7592592592592595|  0.0|\n",
            "+--------------------+------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_predictions.show(800)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VThFDuCY_h7u",
        "outputId": "b01f8625-2fc1-4b08-b981-c9ff8ada2363"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------------+-------------------+------------------+-----+--------------------+--------------------+--------------------+----------+\n",
            "|            features|      rf_prediction|      gb_prediction|     dt_prediction|units|       meta_features|       rawPrediction|         probability|prediction|\n",
            "+--------------------+-------------------+-------------------+------------------+-----+--------------------+--------------------+--------------------+----------+\n",
            "|(5278,[0,5127,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595|  0.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5117,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595|  0.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5106,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595|  0.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5112,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595|  0.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5097,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595|  0.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5109,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595|  0.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5110,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595|  4.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5094,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5087,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5098,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595|  2.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5091,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595|  8.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5095,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5077,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5084,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5020,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595|  6.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5081,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595|  5.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5081,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5003,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595| 11.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5072,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5060,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595|  8.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5061,516...|  1.303025868089093| 0.2693642898780668|0.3143939393939394|  0.0|[1.30302586808909...|[46.7089547307594...|[0.72304019001464...|       0.0|\n",
            "|(5278,[0,5026,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595|  3.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5062,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5093,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5082,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595|  0.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5073,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5037,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5051,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5074,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595|  1.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5053,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  2.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5076,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595|  1.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5057,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5058,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394| 12.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5027,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394| 17.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5027,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595| 46.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5017,518...|  2.915290003885912|0.14685708502379008|0.3143939393939394|  0.0|[2.91529000388591...|[49.2493644555709...|[0.55641600976348...|       0.0|\n",
            "|(5278,[0,5068,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5068,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5068,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5069,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  1.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5045,518...| 1.3545473097074245|0.14685708502379008|0.3143939393939394|  3.0|[1.35454730970742...|[47.8804680282829...|[0.73705740313453...|       0.0|\n",
            "|(5278,[0,5045,518...| 1.3545473097074245|0.14685708502379008|0.3143939393939394|  1.0|[1.35454730970742...|[47.8804680282829...|[0.73705740313453...|       0.0|\n",
            "|(5278,[0,5070,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  1.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5078,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  1.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5078,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5071,518...|0.24066599102610592|0.14685708502379008|0.3143939393939394|  1.0|[0.24066599102610...|[46.9035048406588...|[0.70598838735847...|       0.0|\n",
            "|(5278,[0,5071,518...|0.24066599102610592|0.14685708502379008|0.3143939393939394|  1.0|[0.24066599102610...|[46.9035048406588...|[0.70598838735847...|       0.0|\n",
            "|(5278,[0,5006,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5006,518...|0.45782405889857075|0.14685708502379008|0.3143939393939394|  0.0|[0.45782405889857...|[47.0939698701452...|[0.72457978115077...|       0.0|\n",
            "|(5278,[0,5007,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  3.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5007,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595| 12.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5007,518...|0.45782405889857075|0.14685708502379008|0.3143939393939394|  0.0|[0.45782405889857...|[47.0939698701452...|[0.72457978115077...|       0.0|\n",
            "|(5278,[0,5007,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5008,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  1.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5008,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  1.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5000,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5000,519...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5000,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  2.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5009,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5042,518...| 0.2605938821825685|0.14685708502379008|0.3143939393939394|  0.0|[0.26059388218256...|[46.9209831983081...|[0.70853063868652...|       0.0|\n",
            "|(5278,[0,5042,518...| 0.2605938821825685|0.14685708502379008|0.3143939393939394|  0.0|[0.26059388218256...|[46.9209831983081...|[0.70853063868652...|       0.0|\n",
            "|(5278,[0,5010,519...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  1.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5019,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  1.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5019,518...|0.45782405889857075|0.14685708502379008|0.3143939393939394|  0.0|[0.45782405889857...|[47.0939698701452...|[0.72457978115077...|       0.0|\n",
            "|(5278,[0,5004,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5004,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  1.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5004,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5004,518...|0.45782405889857075|0.14685708502379008|0.3143939393939394|  0.0|[0.45782405889857...|[47.0939698701452...|[0.72457978115077...|       0.0|\n",
            "|(5278,[0,4997,519...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  1.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[4997,5189,...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[4997,5191,...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,4997,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[4997,5183,...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5030,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5030,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[5030,5183,...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[5030,5188,...| 0.2518716779461897|0.14685708502379008|0.3143939393939394|  0.0|[0.25187167794618...|[46.9133331261586...|[0.70744746091001...|       0.0|\n",
            "|(5278,[5030,5184,...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[4999,5183,...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5011,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5011,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5031,516...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  2.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5031,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5031,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[5031,5188,...| 0.2518716779461897|0.14685708502379008|0.3143939393939394|  0.0|[0.25187167794618...|[46.9133331261586...|[0.70744746091001...|       0.0|\n",
            "|(5278,[0,5032,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  1.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[0,5032,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[5024,5167,...|0.43443612449934965| 0.2693642898780668|0.3143939393939394|  0.0|[0.43443612449934...|[45.9471319131906...|[0.72209048061779...|       0.0|\n",
            "|(5278,[0,5024,518...| 0.3545832685130169|0.14685708502379008|0.3143939393939394|  0.0|[0.35458326851301...|[47.0034194228252...|[0.71782905976689...|       0.0|\n",
            "|(5278,[5046,5188,...| 0.2518716779461897|0.14685708502379008|0.3143939393939394|  0.0|[0.25187167794618...|[46.9133331261586...|[0.70744746091001...|       0.0|\n",
            "|(5278,[0,5033,513...|  5.282654889728369|  4.557603682205905|5.7592592592592595|  1.0|[5.28265488972836...|[49.0816044392780...|[0.34322318652488...|       0.0|\n",
            "|(5278,[0,5059,518...| 0.2608659910261059|0.14685708502379008|0.3143939393939394|  0.0|[0.26086599102610...|[46.9212218595719...|[0.70856371889701...|       0.0|\n",
            "|(5278,[5059,5188,...| 0.2518716779461897|0.14685708502379008|0.3143939393939394|  1.0|[0.25187167794618...|[46.9133331261586...|[0.70744746091001...|       0.0|\n",
            "+--------------------+-------------------+-------------------+------------------+-----+--------------------+--------------------+--------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jg6kOO3MglCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f83b81c-eb54-4094-f503-19db95a5a4f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Metrics: {'RMSE': 5.150906253391567, 'MSE': 26.531835231228353, 'MAE': 1.9788381571827973, 'R2': 0.1166540549434748}\n",
            "Gradient Boosting Metrics: {'RMSE': 5.171599405548487, 'MSE': 26.745440411469467, 'MAE': 1.8507877825539305, 'R2': 0.10954232414292431}\n",
            "Decision Tree Metrics: {'RMSE': 5.15461333203553, 'MSE': 26.570038602798427, 'MAE': 1.9873149053256574, 'R2': 0.11538211905702722}\n",
            "Stacking Model Metrics: {'RMSE': 5.753914048864514, 'MSE': 33.10752688172043, 'MAE': 1.7526881720430108, 'R2': -0.10227578932781056}\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(predictions, label_col=\"units\", prediction_col=\"prediction\"):\n",
        "    evaluator = RegressionEvaluator(labelCol=label_col, predictionCol=prediction_col, metricName=\"rmse\")\n",
        "    rmse = evaluator.evaluate(predictions)\n",
        "\n",
        "    evaluator.setMetricName(\"mse\")\n",
        "    mse = evaluator.evaluate(predictions)\n",
        "\n",
        "    evaluator.setMetricName(\"mae\")\n",
        "    mae = evaluator.evaluate(predictions)\n",
        "\n",
        "    evaluator.setMetricName(\"r2\")\n",
        "    r2 = evaluator.evaluate(predictions)\n",
        "\n",
        "    return {\"RMSE\": rmse, \"MSE\": mse, \"MAE\": mae, \"R2\": r2}\n",
        "\n",
        "# Evaluate each model\n",
        "rf_metrics = evaluate_model(rf_predictions, label_col=\"units\", prediction_col=\"rf_prediction\")\n",
        "gb_metrics = evaluate_model(gb_predictions, label_col=\"units\", prediction_col=\"gb_prediction\")\n",
        "dt_metrics = evaluate_model(dt_predictions, label_col=\"units\", prediction_col=\"dt_prediction\")\n",
        "stacking_metrics = evaluate_model(final_predictions, label_col=\"units\", prediction_col=\"prediction\")\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Random Forest Metrics: {rf_metrics}\")\n",
        "print(f\"Gradient Boosting Metrics: {gb_metrics}\")\n",
        "print(f\"Decision Tree Metrics: {dt_metrics}\")\n",
        "print(f\"Stacking Model Metrics: {stacking_metrics}\")\n",
        "\n",
        "# Show final predictions\n",
        "#final_predictions.show(20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the schema of the test dataset\n",
        "test_df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "gEMPXOLoCBrR",
        "outputId": "782081e4-db8a-43dc-8712-6955ba5a2955"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-ac9879f5c082>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Inspect the schema of the test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import monotonically_increasing_id, to_date\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "# Load the test data\n",
        "test_data_path = \"/content/test.csv\"\n",
        "test_df = spark.read.csv(test_data_path, header=True, inferSchema=True)\n",
        "\n",
        "# Convert numeric columns from string to double\n",
        "numeric_columns = [\"ad_spend\", \"unit_price\"]\n",
        "for column in numeric_columns:\n",
        "    test_df = test_df.withColumn(column, col(column).cast(\"double\"))\n",
        "\n",
        "# Add unique identifier to the original test data\n",
        "test_df_with_id = test_df.withColumn(\"unique_id\", monotonically_increasing_id())\n",
        "\n",
        "# Handle date conversion, assuming 'date' needs to be parsed and converted\n",
        "test_df_with_id = test_df_with_id.withColumn(\"date\", to_date(col(\"date\"), \"MM-dd-yyyy\"))  # Adjust date format if needed\n",
        "test_df_with_id = test_df_with_id.withColumn(\"date\", col(\"date\").cast(StringType()))\n",
        "\n",
        "\n",
        "unique_ids_count = test_df_with_id.select(\"unique_id\").distinct().count()\n",
        "print(f\"Unique IDs in test_df_with_id: {unique_ids_count}\")\n",
        "\n",
        "print(f\"Rows in test_df_with_id DataFrame: {test_df_with_id.count()}\")\n",
        "# Generate predictions\n",
        "rf_test_predictions = rf_model.transform(test_df_with_id).select(\"unique_id\", \"features\", \"prediction\").withColumnRenamed(\"prediction\", \"rf_prediction\")\n",
        "gb_test_predictions = gb_model.transform(test_df_with_id).select(\"unique_id\", \"features\", \"prediction\").withColumnRenamed(\"prediction\", \"gb_prediction\")\n",
        "dt_test_predictions = dt_model.transform(test_df_with_id).select(\"unique_id\", \"features\", \"prediction\").withColumnRenamed(\"prediction\", \"dt_prediction\")\n",
        "\n",
        "# Combine predictions\n",
        "meta_test_features = rf_test_predictions.join(gb_test_predictions, on=\"unique_id\", how=\"inner\")\n",
        "meta_test_features = meta_test_features.join(dt_test_predictions, on=\"unique_id\", how=\"inner\")\n",
        "\n",
        "print(f\"Rows in rf_test_predictions DataFrame: {rf_test_predictions.count()}\")\n",
        "\n",
        "\n",
        "# Prepare meta-features for the meta-learner\n",
        "assembler_meta = VectorAssembler(inputCols=[\"rf_prediction\", \"gb_prediction\", \"dt_prediction\"], outputCol=\"meta_features\")\n",
        "meta_test_features_assembled = assembler_meta.transform(meta_test_features)\n",
        "\n",
        "# Generate final predictions\n",
        "final_test_predictions = stacking_model.transform(meta_test_features_assembled)\n",
        "print(f\"Rows in before join  DataFrame: {final_test_predictions.count()}\")\n",
        "# Include original columns with the final predictions\n",
        "final_test_predictions_with_originals = final_test_predictions.join(test_df_with_id, on=\"unique_id\", how=\"inner\")\n",
        "final_test_predictions_with_originals = final_test_predictions_with_originals.select(\n",
        "    \"ID\", \"date\", \"Item Id\", \"Item Name\", \"ad_spend\", \"anarix_id\", \"unit_price\", \"prediction\"\n",
        ")\n",
        "\n",
        "print(f\"Rows in test DataFrame: {test_df.count()}\")\n",
        "print(f\"Rows in predictions DataFrame: {final_test_predictions_with_originals.count()}\")\n",
        "output_path = \"/content/final_predictions2.csv\"\n",
        "final_test_predictions_with_originals.write.mode(\"overwrite\").csv(output_path, header=True)\n",
        "\n",
        "# Show the first few rows\n",
        "final_test_predictions_with_originals.show(20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_0vs-WqB5gy",
        "outputId": "3e80d944-4a0f-451b-f419-c43aab8f3008"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique IDs in test_df_with_id: 2833\n",
            "Rows in test_df_with_id DataFrame: 2833\n",
            "Rows in rf_test_predictions DataFrame: 850\n",
            "Rows in before join  DataFrame: 850\n",
            "Rows in test DataFrame: 2833\n",
            "Rows in predictions DataFrame: 850\n",
            "+--------------------+----------+----------+--------------------+--------+---------+------------------+----------+\n",
            "|                  ID|      date|   Item Id|           Item Name|ad_spend|anarix_id|        unit_price|prediction|\n",
            "+--------------------+----------+----------+--------------------+--------+---------+------------------+----------+\n",
            "|2024-07-01_B0BDRT...|2024-07-01|B0BDRTZTGX|Parent asin - rai...|     0.0| NAPQUEEN|               0.0|       0.0|\n",
            "|2024-07-01_B0B699...|2024-07-01|B0B699PLXD|NapQueen Victoria...|     0.0| NAPQUEEN|               0.0|       0.0|\n",
            "|2024-07-01_B0BDRQ...|2024-07-01|B0BDRQWBK9|NapQueen 5 Inch R...|     0.0| NAPQUEEN|               0.0|       0.0|\n",
            "|2024-07-01_B0CY5Q...|2024-07-01|B0CY5QQ49F|                NULL|   12.43| NAPQUEEN|               0.0|       0.0|\n",
            "|2024-07-01_B0BGDX...|2024-07-01|B0BGDX2Z3L|NapQueen 8 Inch M...|    22.3| NAPQUEEN|           1543.97|       0.0|\n",
            "|2024-07-01_B0BGDX...|2024-07-01|B0BGDXV7FD|NapQueen 8 Inch M...|    0.86| NAPQUEEN|               0.0|       0.0|\n",
            "|2024-07-01_B0BNKY...|2024-07-01|B0BNKYZD2Z|NapQueen 2'' Swir...|    0.31| NAPQUEEN|               0.0|       0.0|\n",
            "|2024-07-01_B0BNKZ...|2024-07-01|B0BNKZ88Z5|NapQueen 3'' Swir...|     0.0| NAPQUEEN|               0.0|       0.0|\n",
            "|2024-07-01_B0BRCX...|2024-07-01|B0BRCXJRX6|NapQueen Anula, F...|   222.2| NAPQUEEN|             129.5|       2.0|\n",
            "|2024-07-01_B0BNL5...|2024-07-01|B0BNL5BKMK|NapQueen 2'' Bamb...|    0.97| NAPQUEEN|               0.0|       0.0|\n",
            "|2024-07-01_B0BRCX...|2024-07-01|B0BRCXCXCV|NapQueen Anula, Q...|   61.11| NAPQUEEN|               0.0|       0.0|\n",
            "|2024-07-01_B0BRCW...|2024-07-01|B0BRCW79VK|NapQueen Anula Gr...|    4.12| NAPQUEEN|               0.0|       0.0|\n",
            "|2024-07-01_B0BRCW...|2024-07-01|B0BRCW2B64|NapQueen Anula Gr...|     0.0| NAPQUEEN|               0.0|       0.0|\n",
            "|2024-07-01_B0BNL3...|2024-07-01|B0BNL3J36Z|NapQueen 2'' Gree...|    0.48| NAPQUEEN|               0.0|       0.0|\n",
            "|2024-07-01_B0BRCX...|2024-07-01|B0BRCXQMS5|NapQueen Anula Gr...|   85.25| NAPQUEEN|               0.0|       0.0|\n",
            "|2024-07-01_B0C9JL...|2024-07-01|B0C9JLKFPZ|NapQueen Anula, Q...|   95.51| NAPQUEEN|               0.0|       2.0|\n",
            "|2024-07-01_B0BRCX...|2024-07-01|B0BRCXQRC9|NapQueen Anula, T...|   60.35| NAPQUEEN|            76.495|       0.0|\n",
            "|2024-07-01_B0BRCY...|2024-07-01|B0BRCYJ33N|NapQueen Anula, T...|  154.31| NAPQUEEN|             214.8|       2.0|\n",
            "|2024-07-01_B0BRCY...|2024-07-01|B0BRCYK4JK|NapQueen Anula Gr...|  178.01| NAPQUEEN| 717.3333333333333|       2.0|\n",
            "|2024-07-01_B0BRCY...|2024-07-01|B0BRCYQNSW|NapQueen Anula Gr...|  435.24| NAPQUEEN|111.10222222222222|       2.0|\n",
            "+--------------------+----------+----------+--------------------+--------+---------+------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rf_model.stages)\n",
        "print(gb_model.stages)\n",
        "print(dt_model.stages)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4REsriwVECHT",
        "outputId": "848dff8a-1ead-4025-e5fa-7001ce78284e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[StringIndexerModel: uid=StringIndexer_0847847726a0, handleInvalid=keep, StringIndexerModel: uid=StringIndexer_096a0020ef4e, handleInvalid=keep, StringIndexerModel: uid=StringIndexer_ca7a31d3d8ab, handleInvalid=keep, StringIndexerModel: uid=StringIndexer_f7be8c49fd9f, handleInvalid=keep, StringIndexerModel: uid=StringIndexer_b2304c2a589a, handleInvalid=keep, OneHotEncoderModel: uid=OneHotEncoder_cd21173c7f42, dropLast=true, handleInvalid=error, OneHotEncoderModel: uid=OneHotEncoder_429f585777ef, dropLast=true, handleInvalid=error, OneHotEncoderModel: uid=OneHotEncoder_03c9b623da3b, dropLast=true, handleInvalid=error, OneHotEncoderModel: uid=OneHotEncoder_4cb882ce841c, dropLast=true, handleInvalid=error, OneHotEncoderModel: uid=OneHotEncoder_baf221a4ed48, dropLast=true, handleInvalid=error, VectorAssembler_fb0ef21e4646, RandomForestRegressionModel: uid=RandomForestRegressor_38686f9a8461, numTrees=20, numFeatures=5278]\n",
            "[StringIndexerModel: uid=StringIndexer_0847847726a0, handleInvalid=keep, StringIndexerModel: uid=StringIndexer_096a0020ef4e, handleInvalid=keep, StringIndexerModel: uid=StringIndexer_ca7a31d3d8ab, handleInvalid=keep, StringIndexerModel: uid=StringIndexer_f7be8c49fd9f, handleInvalid=keep, StringIndexerModel: uid=StringIndexer_b2304c2a589a, handleInvalid=keep, OneHotEncoderModel: uid=OneHotEncoder_cd21173c7f42, dropLast=true, handleInvalid=error, OneHotEncoderModel: uid=OneHotEncoder_429f585777ef, dropLast=true, handleInvalid=error, OneHotEncoderModel: uid=OneHotEncoder_03c9b623da3b, dropLast=true, handleInvalid=error, OneHotEncoderModel: uid=OneHotEncoder_4cb882ce841c, dropLast=true, handleInvalid=error, OneHotEncoderModel: uid=OneHotEncoder_baf221a4ed48, dropLast=true, handleInvalid=error, VectorAssembler_fb0ef21e4646, GBTRegressionModel: uid=GBTRegressor_0095356c0813, numTrees=20, numFeatures=5278]\n",
            "[StringIndexerModel: uid=StringIndexer_0847847726a0, handleInvalid=keep, StringIndexerModel: uid=StringIndexer_096a0020ef4e, handleInvalid=keep, StringIndexerModel: uid=StringIndexer_ca7a31d3d8ab, handleInvalid=keep, StringIndexerModel: uid=StringIndexer_f7be8c49fd9f, handleInvalid=keep, StringIndexerModel: uid=StringIndexer_b2304c2a589a, handleInvalid=keep, OneHotEncoderModel: uid=OneHotEncoder_cd21173c7f42, dropLast=true, handleInvalid=error, OneHotEncoderModel: uid=OneHotEncoder_429f585777ef, dropLast=true, handleInvalid=error, OneHotEncoderModel: uid=OneHotEncoder_03c9b623da3b, dropLast=true, handleInvalid=error, OneHotEncoderModel: uid=OneHotEncoder_4cb882ce841c, dropLast=true, handleInvalid=error, OneHotEncoderModel: uid=OneHotEncoder_baf221a4ed48, dropLast=true, handleInvalid=error, VectorAssembler_fb0ef21e4646, DecisionTreeRegressionModel: uid=DecisionTreeRegressor_e1952ee84bb0, depth=5, numNodes=17, numFeatures=5278]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "04woqg00ECXi"
      },
      "outputs": [],
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "\n",
        "submission = final_test_predictions_with_originals.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "LDprGNw7ECXi"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Rows in test DataFrame: {test_df.count()}\")\n",
        "print(f\"Rows in predictions DataFrame: {final_test_predictions_with_originals.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvYCfuzfENYo",
        "outputId": "0cee1838-75c4-4060-bad8-41a1534cbf6c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows in test DataFrame: 2833\n",
            "Rows in predictions DataFrame: 850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRrfeCEt23w9"
      },
      "source": [
        "# FINAL GBT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fy2r4NneXygA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b842968d-c6b2-49c0-b2e2-c473539b08f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosted Trees Metrics: {'RMSE': 5.256739369268825, 'MSE': 27.633308796420803, 'MAE': 2.369182635836352, 'R2': 0.07998180069042227}\n",
            "+--------------------+------------------+-----+\n",
            "|            features|        prediction|units|\n",
            "+--------------------+------------------+-----+\n",
            "|(149,[0,6,79,92],...| 7.076991406527646|  0.0|\n",
            "|(149,[0,6,79,92],...| 7.076991406527646|  0.0|\n",
            "|(149,[0,6,79,92],...| 7.076991406527646|  0.0|\n",
            "|(149,[0,6,79,92],...| 7.076991406527646|  0.0|\n",
            "|(149,[0,6,79,92],...| 7.076991406527646|  0.0|\n",
            "|(149,[0,6,79,92],...| 7.076991406527646|  0.0|\n",
            "|(149,[0,6,79,92],...| 7.076991406527646|  4.0|\n",
            "|(149,[0,41,80,92]...|1.1722295017657396|  0.0|\n",
            "|(149,[0,41,80,92]...|1.1722295017657396|  0.0|\n",
            "|(149,[0,6,79,92],...| 7.076991406527646|  2.0|\n",
            "|(149,[0,6,79,92],...| 7.076991406527646|  8.0|\n",
            "|(149,[0,41,80,92]...|1.1722295017657396|  0.0|\n",
            "|(149,[0,41,80,92]...|1.1722295017657396|  0.0|\n",
            "|(149,[0,41,80,92]...|1.1722295017657396|  0.0|\n",
            "|(149,[0,6,79,92],...| 7.076991406527646|  6.0|\n",
            "|(149,[0,6,79,92],...| 7.076991406527646|  5.0|\n",
            "|(149,[0,41,80,92]...|1.1722295017657396|  0.0|\n",
            "|(149,[0,6,79,92],...| 7.076991406527646| 11.0|\n",
            "|(149,[0,41,80,92]...|1.1722295017657396|  0.0|\n",
            "|(149,[0,6,79,92],...| 7.076991406527646|  8.0|\n",
            "+--------------------+------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when, lit\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml.regression import GBTRegressor\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"GBTModel\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "data_path = \"/content/df.csv\"\n",
        "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
        "\n",
        "\n",
        "df = df.withColumn(\"units\", when(col(\"units\") < 0, lit(0)).otherwise(col(\"units\")))\n",
        "\n",
        "numeric_columns = [\"ad_spend\", \"unit_price\", \"units\"]\n",
        "for column in numeric_columns:\n",
        "    df = df.withColumn(column, col(column).cast(\"double\"))\n",
        "\n",
        "\n",
        "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "\n",
        "categorical_features = ['Item Id', 'Item Name', 'anarix_id']\n",
        "numeric_features = ['ad_spend', 'unit_price']\n",
        "\n",
        "\n",
        "indexers = [StringIndexer(inputCol=feature, outputCol=feature + \"_index\", handleInvalid='skip') for feature in categorical_features]\n",
        "encoders = [OneHotEncoder(inputCol=feature + \"_index\", outputCol=feature + \"_ohe\") for feature in categorical_features]\n",
        "\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=numeric_features + [feature + \"_ohe\" for feature in categorical_features],\n",
        "    outputCol=\"features\",\n",
        "    handleInvalid=\"skip\"\n",
        ")\n",
        "\n",
        "\n",
        "gbt_regressor = GBTRegressor(featuresCol=\"features\", labelCol=\"units\")\n",
        "\n",
        "pipeline_gbt = Pipeline(stages=indexers + encoders + [assembler, gbt_regressor])\n",
        "\n",
        "\n",
        "gbt_model = pipeline_gbt.fit(train_data)\n",
        "\n",
        "gbt_predictions = gbt_model.transform(test_data).select(\"features\", \"prediction\", \"units\")\n",
        "\n",
        "gbt_metrics = evaluate_model(gbt_predictions, label_col=\"units\", prediction_col=\"prediction\")\n",
        "\n",
        "#  metrics\n",
        "print(f\"Gradient Boosted Trees Metrics: {gbt_metrics}\")\n",
        "\n",
        "gbt_predictions.show(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1Rts-4tptsRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "160f7e1d-967d-4770-eef8-c63485251af4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PipelineModel_c082dab27be3"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "gbt_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lDWBUaeD7Mti",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "d4c4466f-cc22-47b3-9189-8c5e137db014"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test_data_path' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-36632b1ed09a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_data_path' is not defined"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "test_df = spark.read.csv(test_data_path, header=True, inferSchema=True)\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt2UOE_Ewoz_"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, round\n",
        "\n",
        "# Load test data\n",
        "test_data_path = \"/content/test.csv\"  # Update this path to the actual location of your test data\n",
        "test_df = spark.read.csv(test_data_path, header=True, inferSchema=True)\n",
        "\n",
        "# Convert columns to the same numeric format\n",
        "for column in numeric_features:\n",
        "    test_df = test_df.withColumn(column, col(column).cast(\"double\"))\n",
        "\n",
        "# Transform the test data using the trained GBT model pipeline\n",
        "test_predictions = gbt_model.transform(test_df)\n",
        "\n",
        "# Round off the TARGET values to the nearest integer and cast to integer type\n",
        "formatted_predictions = test_predictions.select(\n",
        "    col(\"ID\"),\n",
        "    col(\"prediction\").cast(\"int\").alias(\"TARGET\")  # Cast to integer\n",
        ")\n",
        "\n",
        "# Show the formatted predictions\n",
        "formatted_predictions.show(truncate=False)\n",
        "\n",
        "# Coalesce the DataFrame into a single partition before saving\n",
        "formatted_predictions = formatted_predictions.coalesce(1)\n",
        "\n",
        "# Save the formatted predictions to a CSV file\n",
        "formatted_predictions_path = \"/content/predictions.csv\"  # Update this path as needed\n",
        "formatted_predictions.write.csv(formatted_predictions_path, header=True, mode='overwrite')\n",
        "\n",
        "print(f\"Predictions saved to {formatted_predictions_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_oAVNtP7aq3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "test_df = spark.read.csv(test_data_path, header=True, inferSchema=True)\n",
        "\n",
        "# Get number of rows\n",
        "num_rows = test_df.count()\n",
        "# Get number of columns\n",
        "num_cols = len(test_df.columns)\n",
        "\n",
        "print(\"Shape: ({}, {})\".format(num_rows, num_cols))\n",
        "\n",
        "# To view the first few rows of the DataFrame\n",
        "test_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbux_BSX4CcP"
      },
      "outputs": [],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYUus_H5ypKS"
      },
      "outputs": [],
      "source": [
        "formatted_predictions.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAoVN81ky5FP"
      },
      "outputs": [],
      "source": [
        "formatted_predictions_path = \"/content/formatted_predictions.csv\"\n",
        "formatted_predictions.write.csv(formatted_predictions_path, header=True, mode='overwrite', sep=',')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiyMJJ20zBgc"
      },
      "outputs": [],
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "\n",
        "submission = formatted_predictions.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkA36CufzNYh"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPTbSqGGzQA-"
      },
      "outputs": [],
      "source": [
        "print(f\"Rows in test DataFrame: {test_df.count()}\")\n",
        "print(f\"Rows in predictions DataFrame: {test_predictions.count()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJBIADQS9UyT"
      },
      "outputs": [],
      "source": [
        "# Load test data\n",
        "test_data_path = \"/content/test.csv\"  # Path to your test data file\n",
        "test_df = spark.read.csv(test_data_path, header=True, inferSchema=True)\n",
        "\n",
        "# Get number of rows and columns in the test data\n",
        "num_rows = test_df.count()\n",
        "num_cols = len(test_df.columns)\n",
        "print(f\"Rows in test DataFrame: {num_rows}\")\n",
        "print(f\"Columns in test DataFrame: {num_cols}\")\n",
        "\n",
        "# Show the first few rows of the test DataFrame\n",
        "test_df.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxQAI6RK9Zlp"
      },
      "outputs": [],
      "source": [
        "# Convert columns to double and check for any potential issues\n",
        "for column in numeric_features:\n",
        "    test_df = test_df.withColumn(column, col(column).cast(\"double\"))\n",
        "\n",
        "# Check number of rows after transformations\n",
        "print(f\"Rows after transformations: {test_df.count()}\")\n",
        "test_df.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofLYHDLz77TV"
      },
      "outputs": [],
      "source": [
        "# List columns in the test data and the features used in the model\n",
        "print(f\"Test Data Columns: {test_df.columns}\")\n",
        "print(f\"Model Features: {assembler.getInputCols()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_0tSYc8Dl2y"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "from pyspark.sql.functions import col, round\n",
        "# Start a Spark session\n",
        "spark = SparkSession.builder.appName(\"StackingModel\").getOrCreate()\n",
        "\n",
        "\n",
        "\n",
        "# Load test data\n",
        "test_data_path = \"/content/test.csv\"  # Update this path to the actual location of your test data\n",
        "test_df = spark.read.csv(test_data_path, header=True, inferSchema=True)\n",
        "\n",
        "# Convert columns to the same numeric format\n",
        "for column in numeric_features:\n",
        "    test_df = test_df.withColumn(column, col(column).cast(\"double\"))\n",
        "\n",
        "#\n",
        "# Define the features\n",
        "categorical_features = ['Item Id', 'Item Name']\n",
        "numeric_features = ['ad_spend', 'unit_price']\n",
        "\n",
        "# Define indexers and encoders\n",
        "indexers = [StringIndexer(inputCol=feature, outputCol=feature + \"_index\", handleInvalid='skip') for feature in categorical_features]\n",
        "encoders = [OneHotEncoder(inputCol=feature + \"_index\", outputCol=feature + \"_ohe\") for feature in categorical_features]\n",
        "\n",
        "# Define assembler\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=numeric_features + [feature + \"_ohe\" for feature in categorical_features],\n",
        "    outputCol=\"features\",\n",
        "    handleInvalid=\"skip\"\n",
        ")\n",
        "\n",
        "# Combine all stages into a single pipeline\n",
        "stages = indexers + encoders + [assembler]\n",
        "pipeline = Pipeline(stages=stages)\n",
        "\n",
        "# Fit and transform the training data\n",
        "pipeline_model = pipeline.fit(train_data)\n",
        "assembled_train_data = pipeline_model.transform(train_data)\n",
        "assembled_train_data.printSchema()\n",
        "\n",
        "# Transform the test data\n",
        "assembled_test_data = pipeline_model.transform(test_data)\n",
        "assembled_test_data.printSchema()\n",
        "\n",
        "# Perform predictions\n",
        "test_predictions = gbt_model.transform(assembled_test_data)\n",
        "formatted_predictions = test_predictions.select(\n",
        "    col(\"ID\"),\n",
        "    col(\"prediction\").cast(\"int\").alias(\"TARGET\")  # Round to integer\n",
        ")\n",
        "\n",
        "# Save predictions\n",
        "formatted_predictions_path = \"/content/formatted_predictions.csv\"\n",
        "formatted_predictions.coalesce(1).write.csv(formatted_predictions_path, header=True, mode='overwrite', sep=',')\n",
        "\n",
        "print(f\"Predictions saved to {formatted_predictions_path}\")\n",
        "\n",
        "# Verify the number of rows in test data and predictions\n",
        "print(f\"Rows in test DataFrame: {test_data.count()}\")\n",
        "print(f\"Rows in predictions DataFrame: {test_predictions.count()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmXcL6ZbE9eq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K17p5J5aG-fU"
      },
      "source": [
        "LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFVDEBtBG_Bh"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when, lit\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Start a new Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"LinearRegressionModel\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load data\n",
        "data_path = \"/content/df.csv\"\n",
        "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
        "\n",
        "# Replace negative values in 'units' with 0\n",
        "df = df.withColumn(\"units\", when(col(\"units\") < 0, lit(0)).otherwise(col(\"units\")))\n",
        "\n",
        "# Convert columns to numeric\n",
        "numeric_columns = [\"ad_spend\", \"unit_price\", \"units\"]\n",
        "for column in numeric_columns:\n",
        "    df = df.withColumn(column, col(column).cast(\"double\"))\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Define categorical and numeric features\n",
        "categorical_features = ['Item Id', 'Item Name', 'anarix_id']\n",
        "numeric_features = ['ad_spend', 'unit_price']\n",
        "\n",
        "# Index and encode categorical features\n",
        "indexers = [StringIndexer(inputCol=feature, outputCol=feature + \"_index\", handleInvalid='skip') for feature in categorical_features]\n",
        "encoders = [OneHotEncoder(inputCol=feature + \"_index\", outputCol=feature + \"_ohe\") for feature in categorical_features]\n",
        "\n",
        "# Combine all features into a feature vector\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=numeric_features + [feature + \"_ohe\" for feature in categorical_features],\n",
        "    outputCol=\"features\",\n",
        "    handleInvalid=\"skip\"\n",
        ")\n",
        "\n",
        "# Define the Linear Regression model\n",
        "lr_regressor = LinearRegression(featuresCol=\"features\", labelCol=\"units\")\n",
        "\n",
        "# Create pipeline for Linear Regression model\n",
        "pipeline_lr = Pipeline(stages=indexers + encoders + [assembler, lr_regressor])\n",
        "\n",
        "# Train the Linear Regression model\n",
        "lr_model = pipeline_lr.fit(train_data)\n",
        "\n",
        "# Generate predictions from Linear Regression model\n",
        "lr_predictions = lr_model.transform(test_data).select(\"features\", \"prediction\", \"units\")\n",
        "\n",
        "# Function to evaluate model predictions\n",
        "def evaluate_model(predictions, label_col=\"units\", prediction_col=\"prediction\"):\n",
        "    evaluator = RegressionEvaluator(labelCol=label_col, predictionCol=prediction_col, metricName=\"rmse\")\n",
        "    rmse = evaluator.evaluate(predictions)\n",
        "\n",
        "    evaluator.setMetricName(\"mse\")\n",
        "    mse = evaluator.evaluate(predictions)\n",
        "\n",
        "    evaluator.setMetricName(\"mae\")\n",
        "    mae = evaluator.evaluate(predictions)\n",
        "\n",
        "    evaluator.setMetricName(\"r2\")\n",
        "    r2 = evaluator.evaluate(predictions)\n",
        "\n",
        "    return {\"RMSE\": rmse, \"MSE\": mse, \"MAE\": mae, \"R2\": r2}\n",
        "\n",
        "# Evaluate the Linear Regression model\n",
        "lr_metrics = evaluate_model(lr_predictions, label_col=\"units\", prediction_col=\"prediction\")\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Linear Regression Metrics: {lr_metrics}\")\n",
        "\n",
        "# Show final predictions\n",
        "lr_predictions.show(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lgl9-y1NsgV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOrpPxI6Os-C"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}